import { NextRequest, NextResponse } from 'next/server';
import { Groq } from 'groq-sdk';

/**
 * API endpoint to parse extracted text into optimized fact-checkable claim
 * Uses GPT-OSS-120B to intelligently extract the main claim from extracted text
 */
export async function POST(request: NextRequest) {
  try {
    const { text, source, userMessage } = await request.json();

    if (!text || typeof text !== 'string') {
      return NextResponse.json(
        { error: 'Valid text is required' },
        { status: 400 }
      );
    }

    console.log('ðŸ“ Parsing query from extracted text (source:', source || 'unknown', ')');
    
    // Validate and sanitize user message if provided
    let sanitizedUserMessage: string | undefined = undefined;
    if (userMessage && typeof userMessage === 'string') {
      const trimmed = userMessage.trim();
      if (trimmed.length > 0 && trimmed.length <= 500) {
        sanitizedUserMessage = trimmed;
        console.log('ðŸ“ User message provided:', sanitizedUserMessage);
      } else if (trimmed.length > 500) {
        console.warn('âš ï¸ User message too long, truncating to 500 characters');
        sanitizedUserMessage = trimmed.substring(0, 500);
      } else {
        console.log('ðŸ“ User message is empty, ignoring');
      }
    }

    const groqApiKey = process.env.GROQ_API_KEY;

    if (!groqApiKey) {
      console.warn('âš ï¸ GROQ_API_KEY not configured, returning original text');
      return NextResponse.json({
        claim: text,
        source: 'fallback',
        originalText: text
      });
    }

    const groqClient = new Groq({ apiKey: groqApiKey });

    // Create a prompt to extract the main fact-checkable claim from extracted text
    // Include user message if provided
    const queryParsingPrompt = `You are an intelligent fact-checking assistant. Your task is to analyze the provided text extracted from an image (photocard/news image)${sanitizedUserMessage ? ' along with the user\'s question or message' : ''} and create an optimized fact-checkable claim or statement that should be verified.

${sanitizedUserMessage ? `**IMPORTANT:** The user has written a question or message about the photocard. You MUST incorporate both the extracted text AND the user's message when creating the fact-checkable claim. The user's message is a specific question or context that should guide what needs to be fact-checked.

**Format:**
- Extracted Text from Image: [text from image]
- User's Question/Message: [user's message]

**Your Task:** Create a single, optimized fact-checkable claim that combines relevant information from BOTH the extracted text and the user's message.` : `**Extracted Text from Image:**`}

${sanitizedUserMessage ? `**Extracted Text from Image:**
${text.substring(0, 2000)}

**User's Question/Message:**
${sanitizedUserMessage}

**Important Notes:**
- The user's message is a specific question or context about the photocard
- You MUST consider both pieces of information when creating the claim
- If the user asks a question, incorporate it into the claim format
- If the user provides context or additional information, use it to refine/extract the most relevant claim from the extracted text
- The claim should address what the user wants to verify, not just what's in the image
- If the user asks "à¦•à¦¬à§‡?", "à¦•à§‹à¦¥à¦¾à¦¯à¦¼?", "à¦•à¦¤?", "à¦•à¦¿à¦­à¦¾à¦¬à§‡?", "à¦•à§‡à¦¨?", etc., make sure the claim addresses that specific question
- If the user provides additional context or information, combine it intelligently with the extracted text` : `**Extracted Text from Image:**
${text.substring(0, 2000)}`}

**Instructions:**
1. ${sanitizedUserMessage ? 'Read BOTH the extracted text AND the user\'s message carefully. Understand what the user wants to verify based on their question or message.' : 'Read the extracted text carefully'} and identify the main claim, statement, or assertion that needs to be fact-checked.
2. Create an optimized fact-checkable claim. This should be:
   - A specific, verifiable statement${sanitizedUserMessage ? ' that addresses the user\'s question/message' : ''}
   - ${sanitizedUserMessage ? 'The claim should intelligently combine information from both the extracted text and user\'s message' : 'The main claim or assertion made in the text'}
   - Clear and concise (ideally 10-50 words, maximum 200 words)
   - Focused on what can be fact-checked (specific events, statements, claims, not opinions)
   - Well-formatted with proper grammar and spelling corrections if needed
   - ${sanitizedUserMessage ? 'If the user asked a question, the claim should be formatted to answer that question naturally' : 'If extracted text has OCR errors, correct them intelligently'}
3. If the text contains multiple claims, extract the PRIMARY or MOST IMPORTANT claim${sanitizedUserMessage ? ' that relates to or answers the user\'s question/message' : ''}.
4. ${sanitizedUserMessage ? 'If the user\'s message asks about something specific (e.g., "à¦•à¦¬à§‡?", "à¦•à§‹à¦¥à¦¾à¦¯à¦¼?", "à¦•à¦¤?", "à¦•à¦¿à¦­à¦¾à¦¬à§‡?", "à¦•à§‡à¦¨?", "à¦•à¦¿?", "à¦•à§‹à¦¨?", "à¦•à¦¾à¦¦à§‡à¦°?"), make sure the claim addresses that specific aspect. For example, if user asks "à¦•à¦¬à§‡?", the claim should focus on the timing/date aspect.' : 'If the text is unclear or contains errors from OCR, intelligently correct and clarify it'}.
5. Write the claim in the same language as the text (Bengali or English).
6. The output MUST be ONLY the claim text, no explanations, no JSON format, just the claim itself.

**Examples:**
${sanitizedUserMessage ? `- Extracted text: "à¦ªà§à¦°à¦§à¦¾à¦¨à¦®à¦¨à§à¦¤à§à¦°à§€ à¦¶à§‡à¦– à¦¹à¦¾à¦¸à¦¿à¦¨à¦¾ à¦¨à¦¤à§à¦¨ à¦ªà§à¦°à¦•à¦²à§à¦ª à¦˜à§‹à¦·à¦£à¦¾ à¦•à¦°à§‡à¦›à§‡à¦¨"
  User message: "à¦à¦‡ à¦ªà§à¦°à¦•à¦²à§à¦ª à¦•à¦¬à§‡ à¦¶à§à¦°à§ à¦¹à¦¬à§‡?"
  Claim: "à¦ªà§à¦°à¦§à¦¾à¦¨à¦®à¦¨à§à¦¤à§à¦°à§€ à¦¶à§‡à¦– à¦¹à¦¾à¦¸à¦¿à¦¨à¦¾ à¦˜à§‹à¦·à¦¿à¦¤ à¦¨à¦¤à§à¦¨ à¦ªà§à¦°à¦•à¦²à§à¦ª à¦•à¦¬à§‡ à¦¶à§à¦°à§ à¦¹à¦¬à§‡?"

- Extracted text: "à§¨à§¦à§¨à§© à¦¸à¦¾à¦²à§‡à¦° à¦¬à¦¨à§à¦¯à¦¾à¦¯à¦¼ à¦¸à¦¿à¦²à§‡à¦Ÿ à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£à¦­à¦¾à¦¬à§‡ à¦¡à§à¦¬à§‡ à¦—à¦¿à¦¯à¦¼à§‡à¦›à¦¿à¦²"
  User message: "à¦à¦‡ à¦–à¦¬à¦°à¦Ÿà¦¿ à¦¸à¦¤à§à¦¯ à¦•à¦¿à¦¨à¦¾?"
  Claim: "à§¨à§¦à§¨à§© à¦¸à¦¾à¦²à§‡à¦° à¦¬à¦¨à§à¦¯à¦¾à¦¯à¦¼ à¦¸à¦¿à¦²à§‡à¦Ÿ à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£à¦­à¦¾à¦¬à§‡ à¦¡à§à¦¬à§‡ à¦—à¦¿à¦¯à¦¼à§‡à¦›à¦¿à¦² à¦•à¦¿à¦¨à¦¾"

- Extracted text: "à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶à§‡à¦° à¦…à¦°à§à¦¥à¦¨à§€à¦¤à¦¿ à¦­à¦¾à¦²à§‹ à¦šà¦²à¦›à§‡"
  User message: "à¦•à§‹à¦¨ à¦‰à§Žà¦¸ à¦¥à§‡à¦•à§‡ à¦à¦‡ à¦¤à¦¥à§à¦¯?"
  Claim: "à¦¬à¦¾à¦‚à¦²à¦¾à¦¦à§‡à¦¶à§‡à¦° à¦…à¦°à§à¦¥à¦¨à§€à¦¤à¦¿ à¦­à¦¾à¦²à§‹ à¦šà¦²à¦›à§‡ - à¦à¦‡ à¦¤à¦¥à§à¦¯à§‡à¦° à¦‰à§Žà¦¸ à¦•à§€?"

- Extracted text: "à¦¶à§‡à¦– à¦¹à¦¾à¦¸à¦¿à¦¨à¦¾ à¦¢à¦¾à¦•à¦¾à¦¯à¦¼ à¦à¦•à¦Ÿà¦¿ à¦¸à¦®à¦¾à¦¬à§‡à¦¶à§‡ à¦¬à¦•à§à¦¤à¦¬à§à¦¯ à¦¦à¦¿à¦¯à¦¼à§‡à¦›à§‡à¦¨"
  User message: "à¦à¦‡ à¦¸à¦®à¦¾à¦¬à§‡à¦¶ à¦•à§‹à¦¥à¦¾à¦¯à¦¼ à¦¹à¦¯à¦¼à§‡à¦›à¦¿à¦²?"
  Claim: "à¦¶à§‡à¦– à¦¹à¦¾à¦¸à¦¿à¦¨à¦¾à¦° à¦¬à¦•à§à¦¤à¦¬à§à¦¯à§‡à¦° à¦¸à¦®à¦¾à¦¬à§‡à¦¶ à¦•à§‹à¦¥à¦¾à¦¯à¦¼ à¦¹à¦¯à¦¼à§‡à¦›à¦¿à¦²?"` : `- If extracted text is "à¦ªà§à¦°à¦§à¦¾à¦¨à¦®à¦¨à§à¦¤à§à¦°à§€ à¦¶à§‡à¦– à¦¹à¦¾à¦¸à¦¿à¦¨à¦¾ à¦¨à¦¤à§à¦¨ à¦ªà§à¦°à¦•à¦²à§à¦ª à¦˜à§‹à¦·à¦£à¦¾ à¦•à¦°à§‡à¦›à§‡à¦¨", the claim is: "à¦ªà§à¦°à¦§à¦¾à¦¨à¦®à¦¨à§à¦¤à§à¦°à§€ à¦¶à§‡à¦– à¦¹à¦¾à¦¸à¦¿à¦¨à¦¾ à¦¨à¦¤à§à¦¨ à¦ªà§à¦°à¦•à¦²à§à¦ª à¦˜à§‹à¦·à¦£à¦¾ à¦•à¦°à§‡à¦›à§‡à¦¨"
- If extracted text is about a specific event, extract the main event claim: "à§¨à§¦à§¨à§© à¦¸à¦¾à¦²à§‡à¦° à¦¬à¦¨à§à¦¯à¦¾à¦¯à¦¼ à¦¸à¦¿à¦²à§‡à¦Ÿ à¦¸à¦®à§à¦ªà§‚à¦°à§à¦£à¦­à¦¾à¦¬à§‡ à¦¡à§à¦¬à§‡ à¦—à¦¿à¦¯à¦¼à§‡à¦›à¦¿à¦²"`}

**Output ONLY the claim text (no explanations, no JSON, no markdown):**`;

    const completion = await groqClient.chat.completions.create({
      model: "openai/gpt-oss-120b",
      messages: [
        {
          role: "user",
          content: queryParsingPrompt
        }
      ],
      temperature: 0.3, // Lower temperature for more focused extraction
      max_tokens: 500,
      top_p: 1
    });

    const parsedText = completion.choices[0]?.message?.content || '';
    console.log('ðŸ“ GPT-OSS-120B parsed query:', parsedText);
    
    // Clean the response - remove markdown, JSON markers, explanations
    let cleanedClaim = parsedText.trim();
    
    // Remove markdown code blocks if present
    cleanedClaim = cleanedClaim.replace(/```json\s*|\```/g, '').replace(/```\s*|\```/g, '');
    
    // Remove JSON wrapper if present
    cleanedClaim = cleanedClaim.replace(/^{[\s\S]*?"claim"[\s\S]*?:\s*"([^"]+)"[\s\S]*?}$/i, '$1');
    cleanedClaim = cleanedClaim.replace(/^{[\s\S]*?"query"[\s\S]*?:\s*"([^"]+)"[\s\S]*?}$/i, '$1');
    cleanedClaim = cleanedClaim.replace(/^{[\s\S]*?"text"[\s\S]*?:\s*"([^"]+)"[\s\S]*?}$/i, '$1');
    
    // Remove quotes if wrapped
    cleanedClaim = cleanedClaim.replace(/^["']|["']$/g, '');
    
    // Remove explanations (lines after empty line or after "Claim:" etc.)
    const lines = cleanedClaim.split('\n');
    const claimLines: string[] = [];
    for (const line of lines) {
      const trimmedLine = line.trim();
      // Stop if we hit explanation markers
      if (trimmedLine === '' || 
          trimmedLine.toLowerCase().startsWith('note:') ||
          trimmedLine.toLowerCase().startsWith('explanation:') ||
          trimmedLine.toLowerCase().startsWith('reasoning:') ||
          trimmedLine.toLowerCase().startsWith('context:')) {
        break;
      }
      // Skip JSON structure lines
      if (!trimmedLine.startsWith('{') && !trimmedLine.startsWith('}') && 
          !trimmedLine.includes('"type"') && !trimmedLine.includes('"confidence"')) {
        claimLines.push(trimmedLine);
      }
    }
    
    cleanedClaim = claimLines.join(' ').trim();
    
    // Validate the parsed claim
    if (cleanedClaim && cleanedClaim.length > 10 && cleanedClaim.length < 500) {
      console.log('âœ… Successfully parsed optimized claim using GPT-OSS-120B');
      return NextResponse.json({
        claim: cleanedClaim,
        source: 'gpt-oss-120b',
        originalText: text
      });
    } else {
      console.warn('âš ï¸ Parsed claim validation failed, returning original text');
      // Fallback to original text or first meaningful sentence
      const firstSentence = text.split(/[.!?à¥¤]/)[0];
      const fallbackClaim = firstSentence.length > 20 
        ? firstSentence.substring(0, 200) 
        : text.substring(0, 200);
      
      return NextResponse.json({
        claim: fallbackClaim,
        source: 'fallback',
        originalText: text
      });
    }
  } catch (error) {
    console.error('âŒ Query parsing error:', error);
    // Fallback to original text
    const { text } = await request.json();
    const firstSentence = text?.split(/[.!?à¥¤]/)[0] || '';
    const fallbackClaim = firstSentence.length > 20 
      ? firstSentence.substring(0, 200) 
      : (text?.substring(0, 200) || '');
    
    return NextResponse.json({
      claim: fallbackClaim,
      source: 'error-fallback',
      originalText: text || ''
    });
  }
}

