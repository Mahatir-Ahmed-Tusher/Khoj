import { NextRequest, NextResponse } from 'next/server'
import { tavilyManager } from '@/lib/tavily-manager'
import { GoogleGenerativeAI } from '@google/generative-ai'
import { Groq } from 'groq-sdk'
import { PRIORITY_SITES } from '@/lib/utils'
import { findRelatedArticles } from '@/lib/data'

const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY!)
const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" })
const groq = new Groq({ apiKey: process.env.GROQ_API_KEY! })

// Helper function to create model-specific prompts
function createModelSpecificPrompt(query: string, crawledContent: any[], modelType: 'gemini' | 'openai' | 'deepseek') {
  const baseContent = `
Claim to fact-check: ${query}

Sources found:
${crawledContent.map((item: any, index: number) => `
Source ${index + 1}: ${item.title}
URL: ${item.url}
Language: ${item.isEnglish ? 'English' : 'Bengali'}
Content: ${item.content.substring(0, 1000)}...
`).join('\n')}
`;

  // Base prompt in English for all models
  const basePrompt = `${baseContent}

You are an experienced journalist and fact-checker. Create a detailed, human-friendly, and comprehensive report to verify the following claim:

**Main Claim:** ${query}

**Your Task:**
1. Collect information from available sources
2. Verify the credibility of each source
3. Find consistency in the information
4. Make a clear decision

**Report Structure:**

# Claim
[Write the main claim clearly]

# Verdict
[True/False/Misleading/Unverified - write clearly]

# Detailed Analysis
Include the following topics in this section:

## Primary Information Collection
- What sources we reviewed
- What information we found from each source
- How credible the sources are

## Information Analysis
- How consistent the found information is with each other
- Which information is credible and why
- Which information is questionable and why

## Logic and Evidence
- Explain step by step the logic for reaching the conclusion
- Provide evidence behind each argument
- Use numbered references [1], [2], [3], etc.

## Context and History
- If relevant, explain the history or context behind the event
- Explain why this is important

# Warnings and Limitations
- If any information is unclear or limited
- If more research is needed
- If there are questions about source credibility

# Conclusion
- Summary of main decision
- Why this decision was reached
- What it means for common people

**Important Instructions:**
- Write everything in simple, clear, and human-friendly Bengali
- Explain complex topics simply
- Provide logic at each step
- Be objective and evidence-based
- If using information from English sources, translate and write in Bengali
- Write so readers can easily understand
- Explain complex topics through Q&A or examples
- **CRITICAL:** Do NOT create "Source List" or "Sources" section yourself. Only use the sources provided above.
- No need to provide separate source list at the end of the report.
- **Markdown Formatting:** Use only # and ##. Do NOT use ### or ####.
- **Detailed Writing:** Write at least 3-4 paragraphs in each section.
- **Examples and Analysis:** Provide detailed examples and analysis for each point.

Write the report as if an experienced journalist is writing for their readers - simple, clear, and trustworthy.
**MOST IMPORTANT: This report MUST be detailed and comprehensive. Do NOT write concisely or briefly.**`;

  if (modelType === 'deepseek') {
    return `${basePrompt}

**CRITICAL INSTRUCTION FOR DEEPSEEK:**
You MUST write an EXTENSIVE, DETAILED, and COMPREHENSIVE report. Do NOT be concise or brief. Write as if you are a senior investigative journalist writing for a major newspaper. Your report should be AT LEAST 1500-2000 words.

**Additional DeepSeek Instructions:**
- You MUST write a **detailed and comprehensive report**
- Do NOT write concisely or briefly
- Write at least 1500-2000 words
- Explain each topic in detail
- Fill with examples and analysis
- Write so readers get the complete picture`;
  }

  return basePrompt;
}

// Helper function to generate AI report with three-tier fallback: Gemini â†’ GROQ â†’ DeepSeek
async function generateAIReport(query: string, crawledContent: any[], maxRetries: number = 3): Promise<string> {
  // Step 1: Try Gemini first (gemini-1.5-flash)
  console.log('ðŸ¤– Trying Gemini (gemini-1.5-flash) first...')
  
  const geminiPrompt = createModelSpecificPrompt(query, crawledContent, 'gemini')
  
  // Try Gemini model with retries
  for (let attempt = 1; attempt <= maxRetries; attempt++) {
    try {
      console.log(`ðŸ¤– Generating AI report with gemini-1.5-flash (attempt ${attempt}/${maxRetries})...`)
      const result = await model.generateContent(geminiPrompt)
      const response = await result.response
      return response.text()
    } catch (geminiError: any) {
      console.error(`âŒ Gemini AI error (attempt ${attempt}):`, geminiError)
      
      // Check if it's a rate limit error
      if (geminiError.message && geminiError.message.includes('429')) {
        if (attempt < maxRetries) {
          // Calculate delay with exponential backoff (6s, 12s, 24s)
          const delay = Math.min(6000 * Math.pow(2, attempt - 1), 30000)
          console.log(`â³ Rate limited. Waiting ${delay/1000}s before retry...`)
          await new Promise(resolve => setTimeout(resolve, delay))
          continue
        } else {
          console.log('âŒ Max retries reached for rate limit, trying GROQ...')
          break
        }
      }
      
      // For other errors, try GROQ
      break
    }
  }

  // Step 2: Fallback to GROQ (GPT-OSS-120B)
  console.log('ðŸ”„ Gemini (gemini-1.5-flash) failed, falling back to GROQ...')
  
  try {
    console.log('ðŸ¤– Trying GROQ (openai/gpt-oss-120b)...')
    
    const groqPrompt = createModelSpecificPrompt(query, crawledContent, 'openai')
    
    const chatCompletion = await groq.chat.completions.create({
      "messages": [
        {
          "role": "user",
          "content": groqPrompt
        }
      ],
      "model": "openai/gpt-oss-120b",
      "temperature": 1,
      "max_tokens": 8192,
      "top_p": 1,
      "stream": false,
      "stop": null
    });

    const generatedText = chatCompletion.choices[0]?.message?.content;
    if (generatedText) {
      console.log('âœ… GROQ report generated successfully');
      return generatedText;
    }
  } catch (groqError) {
    console.error('âŒ GROQ error:', groqError);
  }

  // Step 3: Final fallback to DeepSeek
  try {
    console.log('ðŸ”„ GROQ failed, trying DeepSeek (deepseek-r1-0528:free) as final fallback...')
    
    const deepseekPrompt = createModelSpecificPrompt(query, crawledContent, 'deepseek')
    
    const response = await fetch("https://openrouter.ai/api/v1/chat/completions", {
      method: "POST",
      headers: {
        "Authorization": `Bearer ${process.env.OPENROUTER_API_KEY}`,
        "HTTP-Referer": "https://khoj-factchecker.vercel.app",
        "X-Title": "Khoj Fact Checker",
        "Content-Type": "application/json"
      },
      body: JSON.stringify({
        "model": "deepseek/deepseek-r1-0528:free",
        "messages": [
          {
            "role": "user",
            "content": deepseekPrompt
          }
        ],
        "max_tokens": 6000,
        "temperature": 0.7,
        "top_p": 0.9,
        "frequency_penalty": 0.1,
        "presence_penalty": 0.1
      })
    });

    if (response.ok) {
      const data = await response.json();
      const generatedText = data.choices?.[0]?.message?.content;
      if (generatedText) {
        console.log('âœ… DeepSeek report generated successfully');
        return generatedText;
      }
    } else {
      console.log(`âŒ DeepSeek failed with status: ${response.status}`);
    }
  } catch (deepseekError) {
    console.error('âŒ DeepSeek error:', deepseekError);
  }
  
  // Return fallback report if all attempts fail
  return 'AI à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾à¦° à¦•à¦¾à¦°à¦£à§‡ à¦¬à¦¿à¦¸à§à¦¤à¦¾à¦°à¦¿à¦¤ à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à¦¾ à¦¸à¦®à§à¦­à¦¬ à¦¹à¦šà§à¦›à§‡ à¦¨à¦¾à¥¤'
}

export async function POST(request: NextRequest) {
  try {
    const { query } = await request.json()

    if (!query) {
      return NextResponse.json({ error: 'Query is required' }, { status: 400 })
    }



    // Step 1: Search within Bangladeshi news sites for current information
    const bangladeshiNewsSites = [
      'https://www.prothomalo.com',
      'https://www.bd-pratidin.com', 
      'https://www.jugantor.com',
      'https://www.kalerkantho.com',
      'https://www.samakal.com',
      'https://www.thedailystar.net',
      'https://www.bdnews24.com',
      'https://www.dhakatribune.com'
    ]

    let searchResults: any = { results: [] }
    let hasBengaliSources = false
    let hasEnglishSources = false

    // Step 1: Search within Bangladeshi news sites for Bengali content
    try {
      const bangladeshiResults = await tavilyManager.search(query, {
        sites: bangladeshiNewsSites,
        max_results: 11,
        search_depth: "advanced"
      })
      
      if (bangladeshiResults.results && bangladeshiResults.results.length > 0) {
        searchResults.results = bangladeshiResults.results
        hasBengaliSources = true
        console.log(`âœ… Found ${bangladeshiResults.results.length} Bengali sources`)
      }
    } catch (error) {
      console.error('Failed to search Bangladeshi sites:', error)
    }

    // Step 2: If insufficient Bengali sources, search for English sources
    if (!hasBengaliSources || searchResults.results.length < 3) {
      try {
        console.log('ðŸ” Searching for English sources...')
        const englishResults = await tavilyManager.search(query, {
          max_results: 11,
          search_depth: "advanced",
          include_domains: [
            'reuters.com', 'bbc.com', 'cnn.com', 'ap.org', 'factcheck.org',
            'snopes.com', 'politifact.com', 'who.int', 'un.org', 'worldbank.org'
          ]
        })
        
        if (englishResults.results && englishResults.results.length > 0) {
          // If we have Bengali sources, append English sources
          if (hasBengaliSources) {
            searchResults.results = [...searchResults.results, ...englishResults.results.slice(0, 5)]
          } else {
            searchResults.results = englishResults.results
          }
          hasEnglishSources = true
          console.log(`âœ… Found ${englishResults.results.length} English sources`)
        }
      } catch (error) {
        console.error('Failed to search English sources:', error)
      }
    }

    // Step 3: If still no results, try general search
    if (!searchResults.results || searchResults.results.length === 0) {
      try {
        console.log('ðŸ” Trying general search...')
        const generalResults = await tavilyManager.search(query, {
          max_results: 11,
          search_depth: "advanced"
        })
        
        if (generalResults.results) {
          searchResults.results = generalResults.results
          console.log(`âœ… Found ${generalResults.results.length} general sources`)
        }
      } catch (error) {
        console.error('Failed to search general web:', error)
      }
    }

    // Use search results directly without crawling for faster response
    const crawledContent = searchResults.results?.slice(0, 11).map((result: any, index: number) => ({
      title: result.title,
      url: result.url,
      content: (result as any).content || (result as any).snippet || 'Content not available',
      isEnglish: !hasBengaliSources || (hasEnglishSources && index >= searchResults.results.length - 3)
    })) || []

    // Generate fact-checking report with model-specific prompts
    const report = await generateAIReport(query, crawledContent)
    
    // Find related articles from our database
    const relatedArticles = findRelatedArticles(query, 3)
    
    // Add fallback content if AI failed
    const finalReport = report === 'AI à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾à¦° à¦•à¦¾à¦°à¦£à§‡ à¦¬à¦¿à¦¸à§à¦¤à¦¾à¦°à¦¿à¦¤ à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£ à¦ªà§à¦°à¦¦à¦¾à¦¨ à¦•à¦°à¦¾ à¦¸à¦®à§à¦­à¦¬ à¦¹à¦šà§à¦›à§‡ à¦¨à¦¾à¥¤' 
      ? `
## à¦¦à¦¾à¦¬à¦¿
${query}

## à¦¸à¦¿à¦¦à§à¦§à¦¾à¦¨à§à¦¤
à¦…à¦¯à¦¾à¦šà¦¾à¦‡à¦•à§ƒà¦¤

## à¦¬à¦¿à¦¸à§à¦¤à¦¾à¦°à¦¿à¦¤ à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£

**à¦ªà§à¦°à¦¾à¦¥à¦®à¦¿à¦• à¦¤à¦¥à§à¦¯ à¦¸à¦‚à¦—à§à¦°à¦¹:**
à¦†à¦®à¦°à¦¾ à¦à¦‡ à¦¦à¦¾à¦¬à¦¿à¦Ÿà¦¿ à¦¯à¦¾à¦šà¦¾à¦‡ à¦•à¦°à¦¾à¦° à¦œà¦¨à§à¦¯ ${crawledContent.length} à¦Ÿà¦¿ à¦‰à§Žà¦¸ à¦ªà¦°à§à¦¯à¦¾à¦²à§‹à¦šà¦¨à¦¾ à¦•à¦°à§‡à¦›à¦¿à¥¤ à¦†à¦®à¦¾à¦¦à§‡à¦° à¦—à¦¬à§‡à¦·à¦£à¦¾à¦¯à¦¼ à¦¨à¦¿à¦®à§à¦¨à¦²à¦¿à¦–à¦¿à¦¤ à¦‰à§Žà¦¸à¦¸à¦®à§‚à¦¹ à¦…à¦¨à§à¦¤à¦°à§à¦­à§à¦•à§à¦¤ à¦›à¦¿à¦²:

${crawledContent.map((item: any, index: number) => `- ${item.title} (${item.isEnglish ? 'à¦‡à¦‚à¦°à§‡à¦œà¦¿ à¦‰à§Žà¦¸' : 'à¦¬à¦¾à¦‚à¦²à¦¾ à¦‰à§Žà¦¸'})`).join('\n')}

**à¦¤à¦¥à§à¦¯à§‡à¦° à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£:**
à¦¤à¦¬à§‡ à¦¦à§à¦°à§à¦­à¦¾à¦—à§à¦¯à¦¬à¦¶à¦¤, AI à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡ à¦¸à¦¾à¦®à¦¯à¦¼à¦¿à¦• à¦¸à¦®à¦¸à§à¦¯à¦¾à¦° à¦•à¦¾à¦°à¦£à§‡ à¦†à¦®à¦°à¦¾ à¦à¦‡ à¦‰à§Žà¦¸à¦¸à¦®à§‚à¦¹ à¦¥à§‡à¦•à§‡ à¦ªà§à¦°à¦¾à¦ªà§à¦¤ à¦¤à¦¥à§à¦¯à§‡à¦° à¦¬à¦¿à¦¸à§à¦¤à¦¾à¦°à¦¿à¦¤ à¦¬à¦¿à¦¶à§à¦²à§‡à¦·à¦£ à¦•à¦°à¦¤à§‡ à¦ªà¦¾à¦°à¦›à¦¿ à¦¨à¦¾à¥¤

**à¦¯à§à¦•à§à¦¤à¦¿ à¦“ à¦ªà§à¦°à¦®à¦¾à¦£:**
à¦¬à¦°à§à¦¤à¦®à¦¾à¦¨à§‡ à¦†à¦®à¦°à¦¾ à¦¯à§‡ à¦¤à¦¥à§à¦¯à¦—à§à¦²à¦¿ à¦¸à¦‚à¦—à§à¦°à¦¹ à¦•à¦°à¦¤à§‡ à¦ªà§‡à¦°à§‡à¦›à¦¿, à¦¸à§‡à¦—à§à¦²à¦¿ à¦¯à¦¥à§‡à¦·à§à¦Ÿ à¦¨à¦¯à¦¼ à¦à¦‡ à¦¦à¦¾à¦¬à¦¿à¦° à¦¸à¦¤à§à¦¯à¦¤à¦¾ à¦¯à¦¾à¦šà¦¾à¦‡ à¦•à¦°à¦¾à¦° à¦œà¦¨à§à¦¯à¥¤

## à¦¸à¦¤à¦°à§à¦•à¦¤à¦¾ à¦“ à¦¸à§€à¦®à¦¾à¦¬à¦¦à§à¦§à¦¤à¦¾
- AI à¦¸à¦¿à¦¸à§à¦Ÿà§‡à¦®à§‡ à¦¸à¦¾à¦®à¦¯à¦¼à¦¿à¦• à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦°à¦¯à¦¼à§‡à¦›à§‡
- à¦†à¦°à¦“ à¦—à¦¬à§‡à¦·à¦£à¦¾à¦° à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨
- à¦à¦‡ à¦¦à¦¾à¦¬à¦¿à¦Ÿà¦¿ à¦†à¦°à¦“ à¦¯à¦¾à¦šà¦¾à¦‡ à¦•à¦°à¦¾ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨

## à¦‰à¦ªà¦¸à¦‚à¦¹à¦¾à¦°
à¦à¦‡ à¦¦à¦¾à¦¬à¦¿à¦Ÿà¦¿ à¦¸à¦®à§à¦ªà¦°à§à¦•à§‡ à¦à¦–à¦¨à¦‡ à¦•à§‹à¦¨ à¦¸à¦¿à¦¦à§à¦§à¦¾à¦¨à§à¦¤à§‡ à¦ªà§Œà¦à¦›à¦¾à¦¨à§‹ à¦¸à¦®à§à¦­à¦¬ à¦¨à¦¯à¦¼à¥¤ à¦†à¦®à¦°à¦¾ à¦ªà¦¾à¦ à¦•à¦¦à§‡à¦° à¦ªà¦°à¦¾à¦®à¦°à§à¦¶ à¦¦à¦¿à¦šà§à¦›à¦¿ à¦¯à§‡ à¦¤à¦¾à¦°à¦¾ à¦à¦‡ à¦¬à¦¿à¦·à¦¯à¦¼à§‡ à¦†à¦°à¦“ à¦¤à¦¥à§à¦¯ à¦¸à¦‚à¦—à§à¦°à¦¹ à¦•à¦°à§à¦¨ à¦à¦¬à¦‚ à¦¬à¦¿à¦¶à§à¦¬à¦¾à¦¸à¦¯à§‹à¦—à§à¦¯ à¦‰à§Žà¦¸ à¦¥à§‡à¦•à§‡ à¦¯à¦¾à¦šà¦¾à¦‡ à¦•à¦°à§‡ à¦¨à¦¿à¦¨à¥¤

---
à¦à¦‡ à¦°à¦¿à¦ªà§‹à¦°à§à¦Ÿà¦Ÿà¦¿ Khoj à¦«à§à¦¯à¦¾à¦•à§à¦Ÿ à¦šà§‡à¦•à¦¾à¦° à¦¦à§à¦¬à¦¾à¦°à¦¾ à¦¤à§ˆà¦°à¦¿ à¦•à¦°à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤
      `
      : report

    // Determine verdict from report content
    const getVerdictFromReport = (reportText: string): 'true' | 'false' | 'misleading' | 'unverified' => {
      const lowerText = reportText.toLowerCase()
      if (lowerText.includes('à¦¸à¦¤à§à¦¯') || lowerText.includes('true')) {
        return 'true'
      } else if (lowerText.includes('à¦®à¦¿à¦¥à§à¦¯à¦¾') || lowerText.includes('false')) {
        return 'false'
      } else if (lowerText.includes('à¦­à§à¦°à¦¾à¦¨à§à¦¤') || lowerText.includes('misleading')) {
        return 'misleading'
      } else {
        return 'unverified'
      }
    }
    
    const verdict = getVerdictFromReport(finalReport)

    return NextResponse.json({
      claim: query,
      report: finalReport,
      verdict: verdict,
      sources: crawledContent.map((item: any, index: number) => ({
        id: index + 1,
        title: item.title,
        url: item.url,
        snippet: item.content.substring(0, 200) + '...',
        language: item.isEnglish ? 'English' : 'Bengali'
      })),
      relatedArticles: relatedArticles.map(article => ({
        id: article.id,
        title: article.title,
        slug: article.slug,
        summary: article.summary,
        verdict: article.verdict,
        publishedAt: article.publishedAt,
        author: article.author,
        tags: article.tags,
        thumbnail: article.thumbnail
      })),
      sourceInfo: {
        hasBengaliSources,
        hasEnglishSources,
        totalSources: crawledContent.length
      },
      generatedAt: new Date().toISOString()
    })

  } catch (error) {
    console.error('Fact check error:', error)
    return NextResponse.json(
      { error: 'Failed to generate fact-checking report' },
      { status: 500 }
    )
  }
}
