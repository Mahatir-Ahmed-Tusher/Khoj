import { useState, useRef, useCallback } from 'react'

// Define SpeechRecognition interfaces
interface SpeechRecognitionResult {
  [index: number]: SpeechRecognitionAlternative
  length: number
  isFinal: boolean
}

interface SpeechRecognitionAlternative {
  transcript: string
  confidence: number
}

interface SpeechRecognitionResultList {
  [index: number]: SpeechRecognitionResult
  length: number
  item(index: number): SpeechRecognitionResult
}

interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList
  resultIndex: number
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string
  message: string
}

interface SpeechGrammarList {
  [index: number]: SpeechGrammar
  length: number
  item(index: number): SpeechGrammar
  addFromURI(src: string, weight?: number): void
  addFromString(string: string, weight?: number): void
}

interface SpeechGrammar {
  src: string
  weight: number
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean
  interimResults: boolean
  lang: string
  maxAlternatives: number
  serviceURI: string
  grammars: SpeechGrammarList
  start(): void
  stop(): void
  abort(): void
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null
  onend: ((this: SpeechRecognition, ev: Event) => any) | null
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any) | null
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null
  onnomatch: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any) | null
  onsoundstart: ((this: SpeechRecognition, ev: Event) => any) | null
  onsoundend: ((this: SpeechRecognition, ev: Event) => any) | null
  onspeechstart: ((this: SpeechRecognition, ev: Event) => any) | null
  onspeechend: ((this: SpeechRecognition, ev: Event) => any) | null
  onaudiostart: ((this: SpeechRecognition, ev: Event) => any) | null
  onaudioend: ((this: SpeechRecognition, ev: Event) => any) | null
}

interface SpeechRecognitionStatic {
  new (): SpeechRecognition
}

// Extend Window interface for SpeechRecognition
declare global {
  interface Window {
    SpeechRecognition: SpeechRecognitionStatic
    webkitSpeechRecognition: SpeechRecognitionStatic
  }
}

interface UseVoiceSearchReturn {
  isRecording: boolean
  isListening: boolean
  error: string | null
  startVoiceSearch: () => Promise<void>
  stopVoiceSearch: () => void
  isSupported: boolean
}

export const useVoiceSearch = (): UseVoiceSearchReturn => {
  const [isRecording, setIsRecording] = useState(false)
  const [isListening, setIsListening] = useState(false)
  const [error, setError] = useState<string | null>(null)
  const recognitionRef = useRef<SpeechRecognition | null>(null)

  // Check if browser supports speech recognition
  const isSupported = typeof window !== 'undefined' && 
    ('SpeechRecognition' in window || 'webkitSpeechRecognition' in window)

  const requestMicrophonePermission = useCallback(async (): Promise<boolean> => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
      // Stop the stream immediately as we just needed permission
      stream.getTracks().forEach(track => track.stop())
      return true
    } catch (err) {
      console.error('Microphone permission denied:', err)
      setError('à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦«à§‹à¦¨à§‡à¦° à¦…à¦¨à§à¦®à¦¤à¦¿ à¦ªà§à¦°à¦¯à¦¼à§‹à¦œà¦¨à¥¤ à¦…à¦¨à§à¦—à§à¦°à¦¹ à¦•à¦°à§‡ à¦…à¦¨à§à¦®à¦¤à¦¿ à¦¦à¦¿à¦¨à¥¤')
      return false
    }
  }, [])

  const startVoiceSearch = useCallback(async () => {
    if (!isSupported) {
      setError('à¦†à¦ªà¦¨à¦¾à¦° à¦¬à§à¦°à¦¾à¦‰à¦œà¦¾à¦° à¦­à¦¯à¦¼à§‡à¦¸ à¦¸à¦¾à¦°à§à¦š à¦¸à¦¾à¦ªà§‹à¦°à§à¦Ÿ à¦•à¦°à§‡ à¦¨à¦¾à¥¤')
      return
    }

    try {
      setError(null)
      setIsRecording(true)

      // Request microphone permission first
      const hasPermission = await requestMicrophonePermission()
      if (!hasPermission) {
        setIsRecording(false)
        return
      }

      // Initialize speech recognition
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      const recognition = new SpeechRecognition()
      recognitionRef.current = recognition

      // Configure recognition
      recognition.continuous = false
      recognition.interimResults = false
      recognition.lang = 'bn-BD' // Bengali language
      recognition.maxAlternatives = 1

      // Handle recognition start
      recognition.onstart = () => {
        setIsListening(true)
        console.log('ðŸŽ¤ Voice recognition started')
      }

      // Handle recognition result
      recognition.onresult = (event) => {
        const transcript = event.results[0][0].transcript
        console.log('ðŸŽ¤ Voice result:', transcript)
        
        // Dispatch custom event with the transcript
        const voiceSearchEvent = new CustomEvent('voiceSearchResult', {
          detail: { transcript }
        })
        window.dispatchEvent(voiceSearchEvent)
      }

      // Handle recognition end
      recognition.onend = () => {
        setIsRecording(false)
        setIsListening(false)
        console.log('ðŸŽ¤ Voice recognition ended')
      }

      // Handle recognition error
      recognition.onerror = (event) => {
        console.error('ðŸŽ¤ Voice recognition error:', event.error)
        setIsRecording(false)
        setIsListening(false)
        
        switch (event.error) {
          case 'no-speech':
            setError('à¦•à§‹à¦¨à§‹ à¦•à¦¥à¦¾ à¦¶à§‹à¦¨à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿à¥¤ à¦†à¦¬à¦¾à¦° à¦šà§‡à¦·à§à¦Ÿà¦¾ à¦•à¦°à§à¦¨à¥¤')
            break
          case 'audio-capture':
            setError('à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦«à§‹à¦¨ à¦ªà¦¾à¦“à¦¯à¦¼à¦¾ à¦¯à¦¾à¦¯à¦¼à¦¨à¦¿à¥¤')
            break
          case 'not-allowed':
            setError('à¦®à¦¾à¦‡à¦•à§à¦°à§‹à¦«à§‹à¦¨à§‡à¦° à¦…à¦¨à§à¦®à¦¤à¦¿ à¦¦à§‡à¦“à¦¯à¦¼à¦¾ à¦¹à¦¯à¦¼à¦¨à¦¿à¥¤')
            break
          case 'network':
            setError('à¦¨à§‡à¦Ÿà¦“à¦¯à¦¼à¦¾à¦°à§à¦• à¦¸à¦®à¦¸à§à¦¯à¦¾à¥¤ à¦†à¦¬à¦¾à¦° à¦šà§‡à¦·à§à¦Ÿà¦¾ à¦•à¦°à§à¦¨à¥¤')
            break
          default:
            setError('à¦­à¦¯à¦¼à§‡à¦¸ à¦°à§‡à¦•à¦—à¦¨à¦¿à¦¶à¦¨à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤ à¦†à¦¬à¦¾à¦° à¦šà§‡à¦·à§à¦Ÿà¦¾ à¦•à¦°à§à¦¨à¥¤')
        }
      }

      // Start recognition
      recognition.start()

    } catch (err) {
      console.error('Voice search error:', err)
      setError('à¦­à¦¯à¦¼à§‡à¦¸ à¦¸à¦¾à¦°à§à¦š à¦¶à§à¦°à§ à¦•à¦°à¦¤à§‡ à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤')
      setIsRecording(false)
      setIsListening(false)
    }
  }, [isSupported, requestMicrophonePermission])

  const stopVoiceSearch = useCallback(() => {
    if (recognitionRef.current) {
      recognitionRef.current.stop()
    }
    setIsRecording(false)
    setIsListening(false)
    setError(null)
  }, [])

  return {
    isRecording,
    isListening,
    error,
    startVoiceSearch,
    stopVoiceSearch,
    isSupported
  }
}
